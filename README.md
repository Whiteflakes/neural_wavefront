# Neural Wavefront: JWST Phase Retrieval using Deep Learning

<p align="center">
  <em>Predicting wavefront aberrations from Point Spread Functions using Convolutional Neural Networks</em>
</p>

<p align="center">
  <strong>Status:</strong> âœ… Phase 1 Complete (Physics) | â³ Phase 2 In Progress (ML Pipeline)
</p>

---

## ğŸ”­ Overview

This project implements a deep learning solution to the **inverse phase retrieval problem** for the James Webb Space Telescope (JWST). Given an observed Point Spread Function (PSF), we use a Convolutional Neural Network to predict the wavefront aberrations (encoded as Zernike polynomial coefficients) that caused it.

### The Physics in Brief

In optical systems like JWST, a telescope mirror acts as a **Fourier computer**:
- Light from a distant star hits the mirror as a wavefront
- The mirror's geometry and any imperfections create a complex electric field
- This field is Fourier-transformed by the optics to create the image we see
- We only observe the **intensity** (PSF), not the phase information

The challenge: Given the PSF image, recover the wavefront errors that produced it.

**Why is this hard?** When we measure intensity ($|E|^2$), we lose phase information. Many different wavefront errors can produce similar-looking PSFs. Traditional iterative algorithms (like Gerchberg-Saxton) are slow. Deep learning offers a fast, learned approach to this inverse problem.

---

## ğŸ¯ Key Features

- **Physics-Based Simulation**: Accurate Fourier optics modeling of JWST's 18-hexagon aperture
- **Zernike Decomposition**: Wavefront errors represented as orthogonal polynomial basis functions
- **Deep Learning Pipeline**: CNN-based regression from PSF to Zernike coefficients
- **Configuration-Driven**: All parameters externalized to YAML for reproducibility
- **Professional Structure**: Modular codebase following software engineering best practices

---

## ğŸ“ Project Structure

```
neural_wavefront/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml              # Main configuration file
â”‚   â””â”€â”€ experiments/             # Experiment-specific configs
â”œâ”€â”€ src/
â”‚   â””â”€â”€ neural_wavefront/        # Main package namespace
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ optics/              # âœ… Physics simulation modules (COMPLETE)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ pupil.py        # JWST aperture mask generation
â”‚       â”‚   â”œâ”€â”€ zernike.py      # Zernike polynomial computations
â”‚       â”‚   â””â”€â”€ propagation.py  # FFT-based PSF generation
â”‚       â”œâ”€â”€ data/                # Data generation and loading
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ dataset.py      # PyTorch Dataset classes
â”‚       â”‚   â””â”€â”€ generator.py    # Synthetic data creation
â”‚       â”œâ”€â”€ models/              # Neural network architectures
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ resnet.py       # ResNet-based regressor
â”‚       â”‚   â””â”€â”€ loss.py         # Custom loss functions
â”‚       â”œâ”€â”€ training/            # Training infrastructure
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ trainer.py      # Training loop
â”‚       â”‚   â””â”€â”€ metrics.py      # Evaluation metrics
â”‚       â””â”€â”€ utils/               # âœ… Utilities (COMPLETE)
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ config.py       # Config loading
â”‚           â””â”€â”€ visualization.py # Plotting functions
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_data.py        # Data generation script
â”‚   â”œâ”€â”€ train.py                # Training script
â”‚   â””â”€â”€ evaluate.py             # Evaluation script
â”œâ”€â”€ tests/                       # Unit tests
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for exploration
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoints/            # Saved model weights
â”‚   â”œâ”€â”€ figures/                # âœ… Generated validation plots
â”‚   â””â”€â”€ experiments/            # Experiment logs
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/              # Generated datasets (.npz files)
â”œâ”€â”€ AGENT.md                    # Comprehensive development guide
â”œâ”€â”€ STATUS.md                   # âœ… Current development status
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ pyproject.toml              # Package configuration (uv)
```

---

## ğŸš€ Installation

This project uses **uv** for package management.

### Prerequisites
- Python â‰¥ 3.11
- uv package manager ([installation guide](https://github.com/astral-sh/uv))

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/neural_wavefront.git
cd neural_wavefront

# Install dependencies using uv
uv pip install -e .

# (Optional) Install development dependencies
uv pip install -e ".[dev]"
```

---

## ğŸ“Š Quick Start

### 1. Generate Synthetic Data

```bash
uv run python scripts/generate_data.py
```

This creates training, validation, and test datasets by:
- Randomly sampling Zernike coefficients
- Generating JWST aperture masks
- Computing PSFs via FFT
- Saving to `data/processed/jwst_dataset.npz`

### 2. Train the Model

```bash
uv run python scripts/train.py
```

Trains a ResNet-based CNN to predict Zernike coefficients from PSF images. Checkpoints are saved to `outputs/checkpoints/`.

### 3. Evaluate Results

```bash
uv run python scripts/evaluate.py
```

Generates evaluation metrics and visualizations:
- Predicted vs. ground truth coefficient scatter plots
- PSF reconstruction comparisons
- Per-mode error analysis

---

## ğŸ“ The Physics: How It Works

### 1. Wavefront Representation

Any wavefront error can be decomposed into **Zernike polynomials** ($Z_j$):

$$\phi(x, y) = \sum_{j=1}^{N} a_j \cdot Z_j(r, \theta)$$

where:
- $a_j$ are coefficients (what we predict)
- $Z_j$ are orthogonal polynomials (defocus, astigmatism, coma, etc.)

### 2. PSF Generation (Forward Model)

The Point Spread Function is the intensity of the Fourier-transformed pupil field:

$$\text{PSF}(u, v) = \left| \mathcal{F}\left\{ A(x,y) \cdot e^{i\phi(x,y)} \right\} \right|^2$$

where:
- $A(x,y)$ is the JWST 18-hexagon aperture mask
- $\phi(x,y)$ is the wavefront error
- $\mathcal{F}\{\cdot\}$ is the 2D Fourier transform

### 3. Inverse Problem (Neural Network)

Given a PSF image, a CNN learns to predict the coefficients $\{a_j\}$ that produced it.

**Network Architecture**: ResNet-18 backbone
- Input: 256Ã—256 grayscale PSF (log-scaled)
- Output: 15 Zernike coefficients
- Loss: Mean Squared Error (MSE)

---

## ğŸ”§ Configuration

All parameters are defined in [`configs/config.yaml`](configs/config.yaml):

```yaml
simulation:
  grid_size: 256
  wavelength: 2.0e-6      # 2 microns (JWST NIRCam)
  num_segments: 18        # JWST hexagons

zernike:
  max_order: 5
  n_modes: 15

training:
  learning_rate: 0.001
  epochs: 50
  batch_size: 32
```

**No hardcoded values** in source codeâ€”everything is configurable!

---

## ğŸ“ˆ Results

### âœ… Phase 1: Physics Validation

All physics modules have been implemented and validated with visual outputs.

#### Zernike Polynomial Basis

![Zernike Modes](outputs/figures/zernike_modes.png)

*First 8 Noll-indexed Zernike modes on a 256Ã—256 grid. From left to right, top to bottom: Piston (Zâ‚), Tip (Zâ‚‚), Tilt (Zâ‚ƒ), Defocus (Zâ‚„), Astigmatism (Zâ‚…, Zâ‚†), Coma (Zâ‚‡, Zâ‚ˆ). Orthogonality validated numerically.*

#### JWST Aperture Geometry

![JWST Aperture](outputs/figures/jwst_aperture.png)

*Left: JWST 18-hexagonal segment primary mirror mask (512Ã—512 grid). Right: Horizontal cross-section comparison between JWST aperture (blue) and circular reference (orange dashed). Fill factor: 61.13%*

#### PSF Propagation Validation

![PSF Demonstration](outputs/figures/psf_demonstration.png)

*Point Spread Functions generated via FFT-based Fourier optics. Top row: JWST aperture (left) and circular aperture (right) with perfect wavefront showing clean diffraction patterns. Bottom rows: PSFs with various aberrations - defocus (Zâ‚„ = 0.5Î»), coma (Zâ‚‡ = 0.3Î»), and mixed aberrations. Note the characteristic 6-pointed star pattern from JWST's hexagonal geometry.*

### â³ Phase 2: Training Results (Coming Soon)

- Training loss curves
- Predicted vs. true Zernike coefficients
- PSF reconstruction quality
- Per-mode error analysis

---

## ğŸ§ª Development Guide

For AI agents and developers working on this codebase, see **[AGENT.md](AGENT.md)** for:
- Detailed physics derivations
- Implementation requirements and guardrails
- Phase-by-phase development instructions
- Testing and validation criteria

### Running Tests

```bash
pytest tests/
```

### Code Quality

```bash
# Format code
black src/ scripts/ tests/

# Sort imports
isort src/ scripts/ tests/

# Type checking
mypy src/
```

---

## ğŸ“š References

1. **JWST Documentation**: [NASA JWST User Documentation](https://jwst-docs.stsci.edu/)
2. **Zernike Polynomials**: Noll, R. J. (1976). *J. Opt. Soc. Am.* 66(3), 207-211
3. **Phase Retrieval**: Fienup, J. R. (1982). *Applied Optics* 21(15), 2758-2769
4. **Deep Learning for Optics**: [Paine et al. (2018)](https://arxiv.org/abs/1803.03624)

---

## ğŸ“ For Recruiters

This project demonstrates:

- âœ… **Physics & Mathematics**: Fourier optics, wavefront sensing, orthogonal polynomials
- âœ… **Machine Learning**: PyTorch, CNN architectures, training pipelines
- âœ… **Software Engineering**: Modular design, configuration management, testing
- âœ… **Domain Application**: Real-world problem (JWST operations)
- âœ… **Documentation**: Clear explanations, reproducible results

**Key Skills**: Python, Deep Learning, Scientific Computing, Version Control

---

## ğŸ“ License

MIT License (see [LICENSE](LICENSE) file)

---

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Follow the code style (black, isort)
4. Add tests for new functionality
5. Submit a pull request

---

## ğŸ“§ Contact

For questions or collaboration: [your.email@example.com](mailto:your.email@example.com)

---

<p align="center">
  <em>Built with â¤ï¸ for advancing wavefront sensing through deep learning</em>
</p>
