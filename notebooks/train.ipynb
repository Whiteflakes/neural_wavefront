{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf17f43",
   "metadata": {},
   "source": [
    "# JWST Phase Retrieval - Training Notebook\n",
    "\n",
    "This notebook trains a ResNet-18 model to predict Zernike coefficients from PSF images.\n",
    "\n",
    "## üöÄ Google Colab Setup\n",
    "\n",
    "If running on Colab, uncomment and run the setup cells below to:\n",
    "1. Install dependencies\n",
    "2. Clone/upload the project\n",
    "3. Generate training data\n",
    "4. Train the model\n",
    "\n",
    "## üíª Local Setup\n",
    "\n",
    "If running locally, just skip the Colab setup cells and run the training directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca110a2",
   "metadata": {},
   "source": [
    "## üì¶ Install Dependencies (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on Colab\n",
    "# !pip install torch torchvision matplotlib pyyaml tqdm tensorboard scipy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464eeb6",
   "metadata": {},
   "source": [
    "## üìÇ Setup Project (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414919fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on Colab\n",
    "# import os\n",
    "# if not os.path.exists('neural_wavefront'):\n",
    "#     !git clone https://github.com/YOUR_USERNAME/neural_wavefront.git\n",
    "#     os.chdir('neural_wavefront')\n",
    "# else:\n",
    "#     os.chdir('neural_wavefront')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c29bdb",
   "metadata": {},
   "source": [
    "## üîß Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path for imports\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "from neural_wavefront.utils.config import load_config\n",
    "from neural_wavefront.data.dataset import create_dataloaders\n",
    "from neural_wavefront.models.resnet import create_model\n",
    "from neural_wavefront.training.trainer import Trainer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa222d2",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb097618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(\"configs/config.yaml\")\n",
    "\n",
    "# Experiment settings\n",
    "experiment_name = \"colab_training\"  # Change this to customize\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981aa834",
   "metadata": {},
   "source": [
    "## üìä Generate Training Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "train_path = Path(\"data/processed/train.npz\")\n",
    "val_path = Path(\"data/processed/val.npz\")\n",
    "\n",
    "if not train_path.exists() or not val_path.exists():\n",
    "    print(\"‚ö†Ô∏è Data not found. Generating datasets...\")\n",
    "    print(\"This will take a few minutes...\")\n",
    "    \n",
    "    # Run data generation script\n",
    "    import subprocess\n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"scripts/generate_data.py\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ùå Error generating data:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"‚úÖ Data generation complete!\")\n",
    "else:\n",
    "    print(\"‚úÖ Training data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1167077",
   "metadata": {},
   "source": [
    "## üìÅ Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use num_workers=0 on Windows to avoid multiprocessing issues\n",
    "num_workers = 0 if platform.system() == 'Windows' else config['data'].get('num_workers', 4)\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_path=str(train_path),\n",
    "    val_path=str(val_path),\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    num_workers=num_workers,\n",
    "    log_scale=config['visualization'].get('log_scale', True),\n",
    "    normalize_coeffs=False,  # Keep coefficients in radians\n",
    "    augment_train=config['data']['augmentation'].get('enable', True)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Datasets loaded:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Batch size: {config['data']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d79ac8",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057557bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating model...\")\n",
    "model = create_model(\n",
    "    model_name=config['model']['name'],\n",
    "    n_modes=config['model']['output_dim'],\n",
    "    pretrained=config['model']['pretrained'],\n",
    "    dropout=config['model']['dropout']\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ Model: {config['model']['name']}\")\n",
    "print(f\"   Parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed8f69",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer_name = config['training']['optimizer']\n",
    "lr = config['training']['learning_rate']\n",
    "\n",
    "if optimizer_name == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "elif optimizer_name == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "elif optimizer_name == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "\n",
    "# Create loss function\n",
    "loss_name = config['training']['loss']\n",
    "if loss_name == 'MSE':\n",
    "    criterion = nn.MSELoss()\n",
    "elif loss_name == 'MAE':\n",
    "    criterion = nn.L1Loss()\n",
    "elif loss_name == 'Huber':\n",
    "    criterion = nn.HuberLoss()\n",
    "else:\n",
    "    raise ValueError(f\"Unknown loss: {loss_name}\")\n",
    "\n",
    "print(f\"‚úÖ Optimizer: {optimizer_name} (lr={lr:.0e})\")\n",
    "print(f\"   Loss: {loss_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4947eba",
   "metadata": {},
   "source": [
    "## üéØ Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    config=config,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Trainer ready!\")\n",
    "print(f\"   Experiment dir: {trainer.exp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da240b7e",
   "metadata": {},
   "source": [
    "## üöÄ Train Model\n",
    "\n",
    "This cell will train the model for the specified number of epochs. Training progress will be displayed with loss metrics and a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d379f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train\n",
    "n_epochs = config['training']['epochs']\n",
    "\n",
    "print(f\"üöÄ Starting training for {n_epochs} epochs...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Train the model\n",
    "    trainer.train(n_epochs=n_epochs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ Training complete!\")\n",
    "    print(f\"   Best validation loss: {trainer.best_val_loss:.6f}\")\n",
    "    print(f\"   Best model saved to: {trainer.exp_dir / 'checkpoints' / 'best_model.pth'}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    print(f\"   Saving checkpoint...\")\n",
    "    trainer.save_checkpoint('interrupted.pth')\n",
    "    print(f\"   Checkpoint saved to: {trainer.exp_dir / 'checkpoints' / 'interrupted.pth'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c031c8a",
   "metadata": {},
   "source": [
    "## üìä Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7944335",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot training and validation loss\n",
    "epochs = range(1, len(trainer.train_losses) + 1)\n",
    "axes[0].plot(epochs, trainer.train_losses, 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(epochs, trainer.val_losses, 'r-', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation MAE\n",
    "axes[1].plot(epochs, [m['mae'] for m in trainer.val_metrics], 'g-', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('MAE (radians)', fontsize=12)\n",
    "axes[1].set_title('Validation MAE', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(trainer.exp_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Training curves saved to: {trainer.exp_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafaca6c",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "After training is complete, you can:\n",
    "\n",
    "1. **Evaluate the model** on the test set using `scripts/evaluate.py`\n",
    "2. **View TensorBoard logs**: Run `tensorboard --logdir outputs/experiments/{experiment_name}/tensorboard`\n",
    "3. **Load the checkpoint** to continue training or make predictions\n",
    "4. **Download the model** (if on Colab) from the experiment directory\n",
    "\n",
    "The best model is saved at: `outputs/experiments/{experiment_name}/checkpoints/best_model.pth`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
